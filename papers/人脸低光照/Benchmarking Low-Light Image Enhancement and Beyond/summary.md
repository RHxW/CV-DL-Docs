
## 1
low-light image datasets存在的限制：
1. 现存数据集基本只为某一个特定的视觉任务服务。
2. 大多数现存数据集和现实场景的差距较大，而且不同数据集之间的差异也较大。一般包含成对数据的数据集可以分为生成数据和真实成对数据，而这两种都存在限制，对于生成数据而言，模拟的降质可能和真实场景不同；而对于真实成对数据，其对多样性较差，因为固定位置拍摄在现实中其实是受到一定限制的。
3. 现有数据集在图像和人类的联系上关注较少。因为实际的应用一般和人类相关，例如监控视频等。
4. 现有数据集无论在数量上还是多样性上都有待提升。

针对上面提到的数据集的问题，文章提出一个包含人类相关信息的大规模基准数据集VE-LOL(Visual Enhancement in LOw-Light)

**Contributions：**
1. 提出VE-LOL数据集，这个数据集分两部分，一部分是明暗对比的成对数据，另一部分是带人脸标注的低光照图片
2. 针对单张低光照图片增强方法的综述
3. 对比了不同增强方法
4. 在数据集和基准分析的基础上，开发了一个低光照增强优化的人脸检测器

## 2 低光照增强
### 2.1 低光照增强数据集

### 2.2 低光照增强方法
将低光照增强分为七类：直方图均衡化、去雾、统计模型、Retinex模型、深度学习、复合退化和RAW

**Histogram Equalization** 原始的HE通过修改对应直方图，拉伸图片的动态范围从而提升暗光部分的可见度。但是HE是一种全局的调整，会导致局部光照失真。后续的升级通过增加多种限制措施实现了效果的提升。

**Dehazing** 有的方法将低光照图片的反转图像视为有雾的图片，在其上进行去雾操作，然后将这个结果转换回原域作为增强结果。但是这些方法的基础模型都缺乏物理意义上的解释，而且将去噪作为后处理会导致细节模糊。

**Statistical Model-Based Methods** 还有很多方法通过统计学模型对图片的属性进行描述，这种统计学模型的设计都借助了一些专业领域知识。有的是基于物理和统计方法，有的基于数学过程，还有一些则基于图像或视觉感知引导的模型。这些方法在它们各自的专业方向上都获得了较好的结果。但是当输入变得极端的时候，他们的能力就显示出不足了。

**Retinex Theory Based Methods** Retinex模型是一个人类视觉感知模型（其基本思想是人类对某个点的颜色和亮度的感知并不仅取决于该点进入人眼的光线，还和周围其他点的颜色和亮度有关）。后续基于Retinex的方法基本遵循层次分解的范式，将图像分解成两部分：反射和光照。为了进一步抑制噪声并且保留高频细节，提出了一系列机遇Retinex理论的方法。

**Deep-Learning Based Methods** 低光照增强的深度学习发展于2017年。一般来说，通过使用从大规模数据中提取到的强大的先验信息，深度学习方法获取了优越的性能。有些传统方法也被引入到深度网络的设计当中，例如Retinex模型和层次分解方法。

**Compound Degradation and RAW Enhancement** 有的方法希望通过解决其伴随问题（例如去噪和去雾）来解决低光照增强问题。总的来说，这些方法能够在它们假设的条件下获取较好的结果，但是仍然缺少一个能够捕捉并解决所有降质类型的综合性模型。

## 3 
提出一个新的大规模数据集VE-LOL(Vision Enhancement in LOw Light conditions, 低光照条件下的视觉增强)，包含成对数据和带标注的单一数据。该数据集的优点如下：
* 综合考虑：支持高层和底层次视觉评估
* 现实场景
* 多样化
* 与人相关
* 大规模

## 5 ED-TwinsNet for joint Low-Light Enhancement and Face Detection
提出一个包含增强和检测的twins网络，用于提升低光照条件下的人脸检测能力。为了充分利用图像先验信息，在未配对数据中引入一个额外的半循环约束，从而更好地训练一个低光照增强模块。然后这个低光照增强模块作为人脸检测预处理的一部分进行使用。通过将增强和检测阶段的多尺度特征联系起来，可以学习到低光照下鲁棒且有判别能力的用于检测的特征。最后用一个双路融合网络将来自于原图和增强后图片的中间特征进行适应性地融合，用来记得到最终的预测结果。

## 5.1 Problem Formulation
低光照人脸检测可以定义为低光照图像增强P和人脸检测Q的结合：
$$
\begin{aligned}
    [\hat{x}_1, \hat{x}_2,...,\hat{x}_n, f_x]&=P(x) \\
    \hat{\omega}&=Q(x, \hat{x}_1, \hat{x}_2,...,\hat{x}_n, f_x)
\end{aligned}
$$
其中fx是增强阶段提取的特征，$\hat{x}$代表中间增强结果。在人脸检测阶段，Q接受原始输入、中间增强结果和第一阶段提取的特征作为输入并生成$\hat{\omega}$, 目的是生成$\omega$. 人脸检测的性能通常使用IoU来描述。

