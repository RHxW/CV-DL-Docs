# When Does Label Smoothing Help

## Abstract

一个多分类神经网络的泛化能力和学习速度通常可以通过使用对hard target进行加权平均得到的soft target和标签的均匀分布而大幅度提高。通过这种方式对标签进行平滑处理可以防止网络过于自信，而且标签平滑已被用于多个sota模型中，包括图片分类、翻译和语音识别。尽管这一技术已被广泛使用，我们对标签平滑的理解仍然很浅薄。本文从经验上展示除了能够提升泛化能力外，标签平滑技术还可以提升模型准确性，从而显著提升beam-serch效果。但是同样观察到如果一个教师网络通过标签平滑训练得到，那么将其通过知识蒸馏得到的学生网络的效果会变差。为了解释这一现象，我们对标签平滑如何改变网络倒数第二层学习的表达进行了可视化。我们展示了标签平滑可以促进训练样本中同一类的样本表达组成更紧凑的聚类族。这导致了不同类别样本的相似度的logits信息的丢失，这一现象会很大程度影响知识蒸馏，但并不损害模型预测的泛化性或准度。



## 1 Introduction

标签平滑，通过在数据集targets平均分布的加权混合target上而非数据集的hard targets上计算交叉熵而提升精度。

标签平滑已成功在多个领域的深度学习模型提升精度，如图像分类、语音识别和机器翻译。

