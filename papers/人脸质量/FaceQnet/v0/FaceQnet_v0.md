# FaceQnet: Quality Assessment for Face Recognition based on Deep Learning

**Abstract**

提出一个基于深度学习方法用于人脸识别的质量评估方法。由一个卷积神经网络-FaceQnet组成，用于预测输入图像用于人脸识别目的的可用性高低。使用VGGFace2训练FaceQnet. 使用*BioLab-ICAO*框架对VGGFace2的图片进行质量标签的标注。gt质量标签通过FaceNet生成对照评分。使用gt数据微调一个基于ResNet的CNN，使它能够对每张输入图片返回一个质量衡量的数值结果。最后验证FaceQnet的评分是否适合COTS人脸识别系统。

可以得到几条结论：

1）使用已有的*ICAO*框架和一个预训练的CNN自动对数据的质量信息进行标注

2）通过微调一个与训练后的人脸识别网络（ResNet-50）来训练FaceQnet进行质量估计

3）展示了FaceQnet的预测结果与没在开发过程使用的sota商业人脸识别系统的准确率高度相关



## 1. Introduction

人脸识别是一个近年来受到研究人员大量关注的生物识别特征。人脸和其他生物识别特征（如指纹或虹膜）的主要差别之一是其可以在一段距离外、持续且无干扰地获取。大多数场景下，人脸识别系统的精度是其是否可用的主要差别。

一般来说使用人脸做识别与指纹和虹膜相比准确率更低，原因是采集条件的易变性更高。目前人脸识别可以在限制场景下取得高准确率，这种场景下人员配合且采集场景更有利。但是一些最有价值的人脸识别应用是在非限制场景下的，因此需要一个能解决变化因素的能力。

人脸识别系统的性能受样本变化的影响。这种差异与图片的获取条件有关：光照、位置、背景均匀性、对焦、锐度等。其他因素与人脸相关性更大，例如姿态、遮挡的存在和不同的表情。所有这些因素都会影响人脸样本的质量，质量的概念一般认为是一个预测器预测的一张人脸图片用于识别目的的良好程度，也就是说，质量是生物识别性能的估计。

开发一个用于控制人脸样本质量（例如在大型IT系统中有多个图像的采集点，如执法机构识别系统）的监视工具是很有用的。这种工具可以用来提高注册的鲁棒性，或者用来预测生物识别流程的准确程度。其集成于人脸识别系统中的样例见Figure 1. 类似的方法可用于传统的指纹识别，判定当前样本是否能提供用于识别目的的最低质量等级。

![Figure 1](1.png "Figure 1")

本文中我们开发了这样的一个用于人脸质量评估（QA）的基于深度学习的工具。



## 2. Introduction to Face Quality Measures

生物识别中的质量衡量从本质上说是一个函数，它接收一个生物识别样本作为输入，并输出一个该样本的质量估计等级。这个质量等级通常与样本未来的用途相关，或者说当在生物识别系统中使用该样本时，与其预期的识别准确率相关。

我们关注人脸的质量衡量，分类：

* **Groundtruth Definition：** 不同质量衡量方案间最大的差异就是质量好坏的定义。有的方案使用人类的感觉作为gt. 另一些则采用基于性能的gt，得到的质量度量代表输入图像和自动化系统预期的人脸识别性能之间的相关性。
* **Type of Input：** 质量评估（QA）系统可以同样根据它们为了得到质量评估所使用的信息数量进行分类。在全参考（FR, Full-Reference）系统中，一张质量为“好”的图片应该是可用的。系统将探测图像和高质量参考的特征进行对比。在低参考（RR, Reduced-Reference）系统中，只有部分高质量图片的信息是可用的。无参考（NR, No-Refenerce）系统中不适用任何参考的信息。
* **Features Extracted：** 可以从图像提取的特征层面得到人脸质量度量的另一个区别。人脸质量可能受人脸本身的影响，例如：姿态。表情，遮挡；受传感器影响，例如：对比度，分辨率，亮度，焦距，锐度，镜头畸变；或者受环境影响，如：光照，背景。所有这些因素都可以使用人工特征（基于传统数字图像处理技术）或深度学习特征（例如DNN在训练数据基础上自动学习出的特征）来衡量。
* **Output：** 最后，众多QA算法的输出也许是不一致的。有些衡量方式对数据库中的每一张图片预测一个质量的标签，将它们根据质量范围（例：低、中、高质量）进行分类。另一些衡量方式输出一个质量的决策，声明该图片是否符合某个标准。最近的一些方法为每张图片计算一个数值分数（例：0~1之间的数），可以视为一个用来预测一张图片用于人脸识别系统时的预期性能的预测器。

本作提出一个用于人脸识别的基于**深度学习**的质量评估系统。该系统使用**基于性能表现**的gt，针对输入图片预测一个0~1之间的**数值**质量度量而不是用任何其他**参考图片**。质量的度量与识别流程的准确率相关。



## 3. Related Works

Table 1中展示了用于人脸识别的质量评估的一些有价值的相关工作。

![Table 1](t1.png "Table 1")

[1]中的成果是最早的几个用于人脸识别的质量评估方法之一。作者提出了一种基于性能的人脸质量指标（FQI，Face Quality Index）。

他们将从5个数字图像处理（DIP）特征（对比度、亮度、焦距、锐度和光照）中提取出的独立的质量度量合并在一起。他们通过用高斯概率密度函数（PDFs）对评分的分布进行建模，定义了全局FQI. 与PDF均值接近的值代表高质量。这一方法的主要缺点在于使用高斯模型的假设可能无法代表现实场景。

在[6]中，其作者提出了BioLab-ICAO框架，是一个用于自动ICAO合规检验的评估工具。文中定义了30种不同的独立测试项目，由框架对每张输入图片进行测试。输出包括每个测试项目的一个数值分数，0~100. 但是这30个独立的评分并没有合并成一个最终的质量度量结果。

[13]描述的方法使用12个特征，分成三类：DIP特征、图像EXIF头信息中的传感器相关特征和所使用的分类器的特征。作者提取关于这12个特征中哪些与识别性能更相关的结论。

[3]中提出的质量度量与机器精度相关而其他度量和人类对质量的直觉感受相关。作者用Amazon Mechanical Turk服务给Labeled Faces in the Wild数据集中的图片打质量标签。算法的输出是及机器精度和人类直觉质量的预测。他们使用一个预训练的CNN（VGGFace）来提取特征，然后使用这些特征训练一个输出阶段（SVM）。作者总结这两种度量都与识别精度相关，但是人类直觉的度量更准确。

迄今为止，[3]中所提到的方法可以说是人脸质量评估中最先进的方法了。但是它仍有一些缺点：

1）标注数据的人力成本很高

2）需要针对每个用户手动挑选一张高质量图片，用于获取机器精度预测，同样需要人工且会引入偏差。



## 4. Datasets

### 4.1. VGGFace2 Database

本作使用两个从VGGFace2中提取的相互分离的子数据集，一个用于微调我们的QA网络（例，FaceQnet），另一个用于借助一个COTS人脸验证系统来评估质量度量。

完整的数据集包含9131个不同id的331万张图像，每个id平均有362.6张图像。数据集中的所有图片都是从Google Images获取的，都是些名人。这些图片都是在非限制场景下拍摄的，在姿态、年龄、光照等方面有很大差异。样例如Figure 2所示。

![Figure 2](2.png "Figure 2")

VGGFace2的作者同样发表了一个基于ResNet-50的预训练CNN架构。

### 4.2. BioSecure Database

BioSecure Multimodal Database (BMDBA)数据集包含600个人在3种不同场景下采集的生物识别样本。第一个场景的图片是通过远程webcam采集的，第二个是高清相机拍摄的常见的限制场景大头照，背景均匀，第三个非限制场景用手机相机拍摄的室内和室外的照片。

本作中我们使用这个数据集做验证目的。我们使用了第二和第三个场景下的140人的1459张图片使用FaceQnet来获取质量评估。样例间Figure 2的上半部分。



![Figure 3](3.png "Figure 3")



## 5. FaceQnet: Development

我们的系统是基于[3]中成果的扩展。我们的目标是将一张图片的质量和它在人脸识别应用中的精度联系到一起。也就是，我们希望将质量度量量化为一个对照评分。

我们遵循[3]中QA的方法，但是尝试解决它的缺点。做法是：

1）不基于人类直觉生成gt，而采用性能指标

2）使用一个第三方软件来自动获得ICAO对照评分用来对每一个id选择一个高质量图片，从而避免引入人为因素的偏差

我们微调了一个预训练的人脸识别网络（ResNet-50）来进行质量预测。

生物识别质量评估可被视为生物识别精度的一个预测，也就是一个回归问题。主要有两步，如Figure 3所示：

1）用来训练回归模型的gt数据集（图像和gt质量标签）的生成

2）用于回归模型的图像特征选取

### 5.1. Generation of the Groundtruth

一组人脸对照的识别精度与两张对比图片相关：gallary和probe. 对照评分因此依赖于两张图片的质量。因此，质量评估是一个未明确定义的问题：质量度量需要在一个变量（图像$A$）的基础上预测两个变量（图像$A$和$B$）的对比结果。也就是如果两张配对图片的对比评分低，就无法得知这种结果是由$A$的质量造成的，还是$B$或者由二者一同造成。如果不加限制，单独一个对比评分是无法直接用作$A$或$B$的质量gt的。

随之而来的问题就是，我们如何能够生成这样的gt来训练基于对比评分的质量度量？我们做出这样的假设，一张高度合规的ICAO图片就代表高质量。因此如果我们将这张ICAO图片与同一个主体的其他图片配对而对比评分低的话，就可以认为第二张图片的质量低。另一方面，如果评分高，则可认为第二张图片质量高。

这样，通过将图片$B$与同id下的一张完美的ICAO图片$A$作比较，我们就可以使用对比评分作为$B$的质量gt，然后用$B$和它的质量评分来训练FaceQnet. 为了达成这一目的，需要对训练集中的每张图片生成ICAO合规评分。我们会用这些评分选择gallery图片，如最高ICAO评分的图片。如Figure 3中上方所示，使用BioLab框架获取ICAO合规评分。这个框架给每个独立的ICAO合规测试输出一个0~100间的评分。

训练集从VGGFace2中选择了包含300个id的子集。每个id选出一张ICAO合规评分最高的图片作为gallery image. 通过这种方式将训练集分成两部分：gallary images和probe images. 我们决定使用一个预训练的人脸识别用的CNN-FaceNet模型用于对数据集中的图片进行特征提取。这个CNN用CASIA-WebFace数据集进行的预训练。

首先使用FaceNet提取128维的特征向量（通过最后的全连接层）。用这些特征向量计算同一个id的每张gallary images和其他样本的相似度。相似度评分归一化到0~1之间。这样，接近0的值就代表低质量图片（远离ICAO图片），接近1的值代表高质量图片（接近ICAO图片）。本节描述的gt生成的结果用于FaceQnet的训练集。

### 5.2. Regression Model and Training

我们将一个预训练的人脸识别CNN扩展并微调，用来构建FaceQnet的模型。这么做的主要动机是可用数据的数量和质量与精度之间的关系。

微调深度模型来实现一个与原模型功能相近的任务的操作已经成功用于很多研究中了，这些网络用于检测与人脸相关的非id的其他属性，如性别、年龄或者种族。由于质量和精度相关性很强，一个特征向量包含人脸的有分辨力的信息（精度），也就意味着同样包含质量信息。

我们选用ResNet-50模型，并移除了预训练网络的分类层。我们用另外两个全连接层取代最后一层来实现回归：一层将特征向量的维度从2048降到32，输出层输出尺寸为1.

第一个FC层和网络其他层一样用$ReLu$激活函数，输出层不加激活函数。FaceQnet的架构在Figure 3下方展示。

网络的输入是$224\times224\times3$的人脸图像，用MTCNN裁切并对齐。我们冻结了预训练层的参数，只训练新加层。

训练好了之后，FaceQnet可以用作一个黑盒，接收一个人脸图像作为输入，输出一个0~1的与人脸识别精度相关的质量评分。



## 6. FaceQnet: Evaluation



