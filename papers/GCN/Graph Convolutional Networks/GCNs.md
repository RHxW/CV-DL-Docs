# Graph Convolutional Networks(GCNs)

http://tkipf.github.io/graph-convolutional-networks/

## Definitions

当前大多数图神经网络模型普遍都有一种全局的架构，我称之为图卷积网络(GCNs)；卷积，因为滤波器的参数在图的全部位置都共享。

这些模型的目标是在图$\mathcal{G=(V,E)}$上学到一个关于信号或者特征的函数，其接收的输入为：

* 每个节点$i$的特征描述$x_i$;聚合成一个$N\times D$的特征矩阵$X$，$N$为节点的个数，$D$为输入特征的维度
* 一个矩阵形式的图结构的描述；一般以邻接矩阵$A$的形式（或者它的某些函数）

并产生一个节点级的输出$Z$（是一个$N\times F$的特征矩阵，其中$F$是每个节点的输出特征的维度）。图级别的输出可以通过引入某些形式的池化操作来建模。

每个神经网络层都可以写成一个非线性函数
$$
H^{(l+1)}=f(H^{(l)},A),
$$
$H^{(0)}=X,H^{(L)}=Z$（或者对于图级别的输出为$z$），$L$是层数。具体的模型之间的差比仅在于$f(\cdot, \cdot)$的选择和参数化上。



## A Simple Example

作为一个例子，考虑下面这个层级传播法则的非常简单的形式：
$$
f(H^{(l)},A)=\sigma \Big(AH^{(l)}W^{(l)}\Big),
$$
其中$W^{(l)}$是第$l$层的权重矩阵，$\sigma(\cdot)$是一个非线性激活函数，比如$\textbf{ReLU}$. 尽管它的形式很简单，但是这个模型已经很强大了。

但是首先，让我们明确关于这个模型的两个局限：与$A$的乘法意味着对每个节点，将其所有邻居的特征向量进行加和，但是不包括它本身（除非图中存在自循环）。可以通过在图中强制加入自循环来进行“改进”：只需要将单位矩阵加到$A$上即可。

第二个主要的局限是$A$一般是未经归一化的，因此与$A$的乘法可能改变特征向量的值域范围（可以通过查看$A$的特征值来理解）。将$A$归一化成每一行的加和为1，如$D^{-1}A$，其中$D$是对角的顶点度矩阵，可以解决这个问题。现在乘以$D^{-1}A$相当于对邻居节点的特征取平均。实际上当使用一种对称的归一化$D^{-\frac{1}{2}}AD^{-\frac{1}{2}}$时，dynamics变得更有趣（因为这个的和不再仅仅是相邻节点的平均）。合并这两个tricks，基本就得到了<SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS>中引入的传播法则：
$$
f(H^{(l)},A)=\sigma \Big(\hat{D}^{-\frac{1}{2}} \hat{A}\hat{D}^{-\frac{1}{2}} H^{(l)}W^{(l)} \Big),
$$
$\hat{A}=A+I$，其中$I$是单位矩阵，$\hat{D}$是$\hat{A}$的对角度矩阵。



## Embedding the karate club network

看一下上述的这个简单的GCN模型在一个广为人知的图数据集：Zachary's karate club network上的表现如何。

![karate](karate.png"karate")



使用一个3层的GCN，随机初始化权重。现在，在训练权重之前，仅将图的邻接矩阵和$X=I$（单位矩阵，因为我们没有任何节点特征）输入到模型中。这个3层的GCN在前向传播阶段执行三个传播步骤，有效地对每个节点进行三阶卷积（所有节点都到3“跳”之外）。值得注意的是，模型生成一个关于这些节点的embedding，其与图的社区结构(community-structure???)非常相近（见下图）。注意我们是通过随机初始化的权重，而且目前为止并没有进行训练和更新。

![karate_emb](karate_emb.png"karate_emb")

这个结果依序看起来有些令人感到惊讶。最近有一篇关于一个校准DeepWalk模型的文章展示了它们可以在一个复杂的无监督训练过程中学习到一个很类似的embedding. 怎么可能使用我们没有经过训练的的简单GCN模型获得这样的embedding？

我们可以通过将GCN解释成一个作用于图上的泛化且可微版的Weisfeiler-Lehman算法来阐明这一现象。一维的Weisfeiler-Lehman算法的机制为：

对所有的节点$v_i\in\mathcal{G}$:

* 得到邻近节点$\{v_j\}$的特征$\{h_{v_j}\}$
* 更新节点的特征$h_{v_i} \leftarrow \textbf{hash}(\sum_jh_{v_j})$，其中$\textbf{hash}(\cdot)$是（理想情况）一个单射的哈希函数。

重复$k$步直到收敛。

实际上，对于大多数图来说，Weisfeiler-Lehman算法指定了独特的一组特征集合。这意味着每个节点都被分配了一个特征，而这个特征可以唯一地描述它在整个图中所扮演的角色。特例是那些高度规则的图，比如grids，chains等。对于大多数不规则图而言，这个分配特征的操作可以用作检验图的同构性（比如两个图是否一样，up to a permutation of nodes）。

回到我们的图卷积层级传播法则（现在是向量形式）：

$h_{v_i}^{(l+1)}=\sigma \Big(\sum\limits_j \frac{1}{c_{ij}}h_{v_j}^{(l)}W^{(l}\Big),$

其中$j$指向节点$v_i$的邻近节点。$c_{ij}$是边$(v_i,v_j)$的一个归一化的常数，来源于在GCN模型中使用对称归一化邻接矩阵$D^{-\frac{1}{2}}AD^{-\frac{1}{2}}$. 现在可以看到这一传播法则可以解释成原始Weisfeiler-Lehman算法的哈希函数中的一个可微的参数化（通过$W^{(l)}$进行的参数化）变量。如果我们现在选择一个合适的非线性方法并随机初始化权重矩阵使其正交，那么这一更新法则在实际中就会变得稳定（同样也得益于使用$c_{ij}$进行归一化）。得到了有意义的平滑embeddings，可以将距离解释成图局部结构的相似度（反相似度）。



## Semi-supervised learning

由于模型中的所有东西都是可微且参数化的，我们就可以加入一些标签来训练模型然后观测embeddings的反映。可以使用半监督学习算法，只对每个类别或社区(class/community)的一个节点给出标签（视频中高亮的节点），并开始训练几次迭代：

<video id="video" controls="" preload="none">
    <source id="mp4" src="video.mp4" type="video/mp4">
</video>

> 使用GCNs的半监督分类：每一类给一个标签，训练300次迭代后的动态隐空间。

注意到模型直接产生了一个我们可以直接观测到的二维隐空间。可以看到这个三层的GCN模型能够在每个类别只给一个标签的前提下将这些communities线性分离。这是一个了不起的结果，因为模型并没接收节点的特征描述。