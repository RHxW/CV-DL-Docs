# Inductive Representation Learning on Large Graphs(GraphSAGE)

## Abstract
大规模图的节点低维嵌入法应用广泛，效果也好。但是目前大多数实现方法都需要图中所有节点参与训练；这些方法本质上是直推式(transductive)的而且无法直接泛化到没见过的节点。本文提出GraphSAGE，一个一般的归纳式框架，利用节点特征信息生成预先未见过的节点嵌入。与为每个节点训练其独立的嵌入不同，我们学习一个函数通过采样和聚合一个节点的局部邻居节点的特征来生成嵌入。

## 1 Introduction
大规模图节点的低维嵌入向量在很多任务中都可以作为很有用的输入特征来使用。节点嵌入法背后的思想是利用降维技术对图中节点的邻居的高维信息进行蒸馏得到一个稠密的向量。然后可以将这些节点向量送入后续的机器学习系统来完成不同的任务，比如节点分类、聚类和连接预测。

但是之前的工作都关注于一个单一固定图的节点嵌入，而很多现实任务都需要快速生成没见过节点或者整个新（子）图的嵌入。对于高吞吐的生产环境机器学习系统而言，这一归纳能力是必须的，因为它需要在不断进化的图上进行操作，而且会一直遇到没有见过的节点。一个归纳的生成节点嵌入的方法也可以促进拥有同样形式特征的不同图间的泛化能力：例如可以在一个模型有机体上训练一个蛋白质-蛋白质相互作用图嵌入生成器，然后迁移到一个新的有机体上利用现有模型生成数据。

与直推式的设定相比，归纳式节点嵌入问题格外困难，因为泛化到没见过的节点需要将新观察的子图与算法已经优化郭的进行“对齐”。一个归纳式框架必须学习识别一个节点的邻居的结构属性，这样的结构属性可以揭示节点在图中的局部角色和它的全局位置。

大多数现有方法都采用直推式生成节点嵌入。其中大多数方法通过使用基于矩阵分解的目标来直接优化每个节点的嵌入，因为它们在单一的固定图上进行预测，所以不能直接泛化到没见过的数据。这种方法可以通过修改变成归纳式方法，但是修改会增加计算复杂度，生成新预测前需要额外的梯度下降轮数。GCNs同样是直推式的方法，它也做用于固定图。本作干了两件事，一是将GCNs扩展到归纳式无监督学习，另一个是提出一个框架，将GCNs泛化来使用可训练的聚合函数（超越简单卷积）。

**当前工作** 
提出一个用于归纳式节点嵌入的通用框架，称为GraphSAGE(SAmple and aggreGatE).与基于矩阵分解的嵌入方法不同，我们利用节点特征（如文本属性、节点描述信息、节点度）来学习一个能够泛化到没见过节点的嵌入函数。通过在学习算法中结合节点特征，我们同时学习每个节点邻居的拓扑结构，以及节点特征在邻居中的分布。虽然我们关注特征丰富的图（例如带文本信息的引用数据，带公式/分子式标记的生物数据），但是我们的方法同样能够利用整个图的结构特征（如节点的度）。因此我们的算法同样可以应用于没有节点特征的图（？？？）。

我们不是针对每个节点训练一个明确的嵌入向量，而是训练一组聚合器函数，让它们学习去从一个结点的邻居中聚合特征信息(Figure 1).每个聚合器函数都从给定节点的不同跳数，或称为搜索深度处聚合信息。测试或推理的时候，使用训练好的系统，在全部没见过节点上应用学习后的聚合函数来生成它们的嵌入。根据之前生成节点嵌入的工作，设计一个无监督损失函数，它可以允许GraphSAGE脱离特定任务监督而训练。同时GraphSAGE也可以通过全监督的方式来训练。

在三个节点分类的基准上进行了测试，blahblahblah

## 2 Related work
**Factorization-based embedding approaches.** 一些最近的节点嵌入方法通过使用随机游走策略和基于矩阵分解的学习目标来学习低维嵌入。这些这些方法也和其他的一些经典算法联系紧密，例如谱聚类，多维缩放，以及PageRank算法。由于这些嵌入算法是针对独立的节点直接训练节点嵌入，因此它们本质上是直推式的，而且至少需要通过大量的额外训练才能在新节点上进行预测。