# Structure-Aware Face Clustering on a Large-Scale Graph with 10^7 Nodes

## Abstract

STructure-AwaRe Face Clustering（STAR-FC）方法，设计了一个能够保留结构信息的子图采样策略，用于探索大规模训练数据的能量，可将训练数据的尺度从1e5提升至1e7. 推理的时候STAR-FC在整个图上进行聚类，两个步骤：图解析(graph parsing)和图微调(graph refinement). 第二步引入节点亲密度(node intimacy)来挖掘局部结构信息。

![Figure 1](1.png"Figure 1")

## 1. Introduction

基于GCN的监督学习聚类方法是通过邻接图来实现的，一般可以分为两类：局部方法和全局方法，区别在于GCN的输入是否是整个图。

提出一个结构感知人脸聚类方法STAR-FC来解决大规模训练和高效推理的困境。特别地设计一个基于knn图的GCN来估计边的置信度。进一步提出保留结构的子图采样策略用于进行大规模GCN训练。推理的时候，分两步继续宁人脸聚类：图解析和图微调。第二步中，引入节点亲密度来挖掘局部结构信息用于后续微调。在推理过程，整张图都会作为输入以提升效果。

实验表明，在这些结构感知设计的帮助下，STAR-FC不仅可以实现基于采样的训练，还可以实现全图推理。基于采样的训练中，训练数据能够提升两个数量级，从1e5到1e7.甚至更高。



## 2. Related Work

blahblahblah



## 3. Methodology

### 3.1. Overview

STAF-FC的总体结构见Figure 2

![Figure 2](2.png"Figure 2")

训练的时候通过保留结构的子图采样策略来训练基于GCN的边置信度估计器。目标是通过采样的子图来近似整个图的结构，并保留大多数对训练贡献较大的困难负样本（边）。通过这种方式就可以释放大规模数据的潜力。我们将边的预测建模成一个二分类问题，并使用交叉熵损失作为监督。推理的时候，将人脸聚类分为两步：图解析和图微调。图解析是将整个图作为输入来估计全部边的置信度得分。然后将得分较低的边从图中移除，此时图的结构变得更清晰。但是其中仍然存在错误的连接。这些错误的链接评分相对较高，因此难以去除。为了对图做进一步的调整，引入节点亲密度进行再次剪枝。这两步完成之后，人脸聚类族就自然形成了。

### 3.2. Large-Scale GCN Training

**Design of the GCN. ** 这一步设计一个基于GCN的，在knn邻接图上使用的边置信度预测器。首先使用一个训练好的ResNet-50获得特征矩阵$F\in \mathbb{R}^{N\times D}$，其中$N$是人脸图片的数量，$D$是特征的维度。为了构建knn邻接图，每个样本都当作图中的一个节点，并连接到$K$个最近的相邻节点。对应的稀疏对称邻接矩阵是$A \in \mathbb{R}^{N\times N}$.

因为CNN通过强监督进行训练，它提取的特征$F$实际上就包含了丰富的身份信息。但是由于类内差异和knn固定的$K$值，邻接图可能会包含很多错误的边。因此使用GCN进相邻信息的传播，尝试直接预测边是否应该保留。使用的GCN骨干网络，一个$L$层的计算过程可以表示为：
$$
F_{l+1}=\sigma \Big( [F_l^T,(\tilde{A}F_l)^T]^TW_l \Big), \qquad(1)
$$
其中$\tilde{A}=\tilde{D}^{-1}(A+I)$. $\tilde{D}$是对角的度矩阵，$\tilde{D}=\sum_j\tilde{A}_{ij}$. $F_l$代表第$l$层的embeddings，$F_0$是输入的人脸特征。$W_l \in \mathbb{R}^{D_{in}\times D_{out}}$是可学习的矩阵，将embeddings映射到一个新的空间。$\sigma$是一个非线性激活函数，使用的是ReLU. $F_L$代表$L$层的输出。

由于$F_L$将相邻节点的很多信息聚合到一起并对图的结构信息进行编码，这使它更适合人脸聚类任务。为了预测边是否保留，设计了一个2层MLP的二分类网络，使用边置信度和gt计算交叉熵loss. 具体操作是将一条边所连接的一对特征作为MLP的输入得到边置信度的预测值。边的gt label是0或1

这样就可以通过一个阈值$\tau_1$来去掉错误的边。但是这样可能导致两种误判：1）可能去掉了少数的正确边；2）可能保留了少数的错误边；由于原始的邻接图的连接很稠密，所以丢失正确边对结果的影响很小。

**Structure-Preserved Subgraph Sampling. ** GCN的训练中，全局方法显存跟不上，局部方法缓解了显存的负担但同时严重依赖于重叠的子图，因此在效率和精度上都受到严重的影响。

为了充分利用大规模数据集，设计了一个保留结构的子图采样(SPSS, structure-preserved subgraph sampling)策略用来训练GCN. 一个邻接图中的边主要由两部分组成：稠密的类内连接和稀疏的临近类间连接。与之前在节点上随机采样的方法不同，我们的方法将人脸聚类族视为最小的采样单元，尝试近似类内的稠密连接。进一步对这些类内连接进行建模，将子图从选中的聚类族扩展到与之相邻的聚类族。一方面，采样得到的子图保留了整个图的重要的结构信息，即类内的连接和相邻类间的连接。另一方面，许多相近的类被采样到一个子图中，这些相邻类间的连接可视为困难样本，并对GCN的训练做出较大贡献。通过使用这个保留结构的子图采样策略，我们的方法可以从增加的训练数据中获益。有趣的是这一采样策略不会引起性能的下降，因为整个图的结构信息都被考虑在内。另外，Table 2中的实验结果表明增强的泛化性可以带来进一步的性能提升。

![Algorithm 1](a1.png"Algorithm 1")

Algorithm 1展示了SPSS的细节。在聚类族中经过重新组织后的节点上随机选择$M$个聚类作为采样seeds. 对每个seed 聚类族，扩展到其$N$个最近邻聚类族，距离通过聚类族中心的余弦相似度计算得到。至此，可以得到子图$\mathcal{S}_1$，包含$M\times N$个聚类。为了进一步增强泛化性，引入聚类随机(CR, cluster randomness)策略：从$\mathcal{S}_1$中随机选择$K_1$个聚类，以及采样随机(SR, sample randomness)策略：从$\mathcal{S}_2$中随机选择$K_2$个节点。然后根据这些采样得到的节点重建子图$\mathcal{S}$的KNN图。

![Figure 3](3.png"Figure 3")

### 3.3. Efficient Face Clustering Inference

**Graph Parsing. ** 这一步中，使用训练好的GCN初步解析构建的邻接图。将整个图传入GCN然后同时得到每条边的评分。Figure 3中可以看到预测得到的分数分布在0和1的位置很陡峭。因此可以使用一个阈值$\tau_1$进行简单而高效的剪枝。这一步中可能会有一小部分正确的边被错误的剪掉了。然而由于初始的邻接图的连接是稠密的，这一现象对最终聚类结果的影响很小。这一步之后，大多数错误的连接都被去掉了，图的结构变得更清晰。但是其中仍存在少量的假阳的边。为了处理这种边，在第二步中引入了节点亲密度用于挖掘局部图结构。

**Graph Refinement. ** 剩下的假阳的边错误地将不同的类连到了一起，这会严重影响到最终的聚类表现。这些边不能通过得分直接排除，因此想要通过节点亲密度(NI, node intimacy)来定位到它们。

节点亲密度的概念受人类的熟悉度启发。在人类社会中，两个关系相近的人通常拥有很多共同的朋友。将这一想法推广到图上，建立了节点亲密度的概念。实际上，给定两个节点$\mathcal{N}_1,\mathcal{N}_2$. 有$n_1$条边连接到$\mathcal{N}_1$，有$n_2$条边连接到$\mathcal{N}_2$. 节点$\mathcal{N}_1$和$\mathcal{N}_2$有$k$个相同的邻居。则将$\mathcal{N}_1,\mathcal{N}_2$间的NI表示为：
$$
NI=Aggregation(\frac{k}{n_1}, \frac{k}{n_2}), \qquad (2)
$$
常见的聚合(aggregation)操作包括平均、最小和最大。4.2节中进行的比较表明最大函数的效果最好。Figure 4 演示了图上的NI并展示了计算结果。

![Figure 4](4.png"Figure 4")

进一步将上述计算通过矩阵操作来实现。给定邻接矩阵$A \in \mathbb{R}^{N\times N}$, 所有节点对的共同邻居节点个数为$\tilde{A}=AA$, 其中$\tilde{A}$的每个元素$\tilde{a}_{ij}$代表第$\mathcal{N}_j$和$\mathcal{N}_j$节点的共同的邻居节点数。那么NI就可以表示为：
$$
NI=\max((\tilde{A^T}sum_0)^T,\tilde{A}sum_1), \qquad (3) \\
sum_0=vec({\sum_j a_{\cdot j}}^{-1}), \quad sum_1=vec({\sum_j a_{i \cdot}}^{-1}),
$$
推理的时候使用节点亲密度来表示边的得分并移除得分低于$\tau_2$的边。这一步完成后，可以认为大多数错误的连接都被排除掉了。就可以直接从图上获取人脸聚类结果了。

