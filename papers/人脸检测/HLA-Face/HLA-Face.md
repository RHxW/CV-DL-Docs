# HLA Face
## Abstract
大多数现有的人脸检测器严重依赖于大量标注数据，为了减轻构建低光照场景数据的负担，提出利用现有的正常光照数据并探索如何让正常光照的人脸检测器适应低光照场景。这个任务最大的挑战是正常光照和低光照场景间的无论在像素级别上还是目标级别上都存在的巨大domain gap.为了解决这一问题，提出一个联合High-Low Adaption(HLA)框架。通过一个双向低级适应和一个多任务高级适应方式能够达到sota性能，甚至不需要使用dark face标签进行训练。

## 1. Introduction
为了适应正常光照到低光照的变化，提出一个High-Low Adaptation 人脸检测框架(HLA-Face).考虑将低级和高级匹配(adaption)联合在一起。具体来说，对于低层级匹配，典型的方法是将暗图片变亮或者将亮图片变暗。但是由于存在巨大的domain gap，这些方法无法达到令人满意的效果。与这些单方向方法不同，我们采用双向的方法，使两个domain都进行变化，向彼此靠拢。通过增强暗图片的亮度和将正常光照图片失真的操作，构建两个domain间的中间状态。对于高层级匹配，采用多任务自监督学习以减少与低层级构建的中间状态特征的距离。通过结合高低层级匹配得到了sota的检测效果。主要贡献如下：
* 提出一个不需要暗场景数据标注的黑暗人脸检测框架
* 为低层级匹配设计了一个双向模式。
* 为高层级匹配引入了跨域自监督学习

## 2. Related Work

![Figure 2](2.png 'Figure 2')

## 3. Joint Adaptation for Dark Face Detection
![Figure 3](3.png 'Figure 3')
### 3.1. Motivation
目标是使在正常光照数据H上训练的人脸检测器泛化到低光照数据L上。如Figure 2所示，当前的方法可以大概分为3类：增强法，暗化法以及特征适应法。
基于**增强**的方法会亮化低光照图片并直接在上面进行测试，通常不需要模型微调，因此很灵活。
基于**暗化**的方法首先对正常光照的图片进行暗化，然后用这些暗化后的图片再对模型进行训练。增强方法和暗化方法都是像素级的方法。
**特征适应**方法一般采用对齐、对抗学习或者伪标签等手段直接适应模型特征。

暗光人脸检测的问题在于H和L间的domain gap非常大，而且对于现有的方法过于复杂。如Figure 3所示，WIDER FACE和DARK FACE的图片见不仅存在像素级的差异而且其内容也有很大不同。
然而增强和暗化方法仅考虑了像素级别的差异。特征适应方法则尝试在一步操作中填补这种gap

为了同时解决黑暗人脸检测的像素级和特征级的gap，提出一个高低匹配方法。如Figure 2(e)所示，设置好低层级上L和H的中间状态，然后根据这些状态对高层级表示进行匹配。与H-to-L或者L-to-H的单向变换相比，我们采用的双向变换：L-to-E(L)和H-to-D(H)不仅能够降低匹配的难度，也可以提供特征级别匹配的工具。高层级上距离的减小是通过将多状态的特征空间相互靠近实现的。

框架的细节如Figure 4所示。

### 3.2. Bidirectional Low-Level Adaptation
低层级匹配的困难主要有两方面：
1. 与高层级gap的联系，例如Figure 5展示了一些H到L的变换方法
2. 低光照增强本身的困难，当前的低光照增强方法主要是为了人类视觉设计的而非机器视觉，当前的去噪和色彩重建方法对一些极端情况不够鲁棒。
![Figure 4](4.png 'Figure 4')
![Figure 5](5.png 'Figure 5')
为了解决这些问题提出了双向低级匹配方法。低光照降质是一个复杂的过程。可以粗略地分解成三个方面：光照、噪音和色彩偏置。虽然去噪声和色彩纠正比较困难，但是反过来去加噪声和加色彩偏差相对容易。

因此，将L增强到E(L),并将H失真到D(H)，这样和H与L相比，E(L)和D(H)间的差异更小。通过这种都向中间状态靠近一步的方式降低了H和L在匹配时的难度。还通过对低光照降质进行单独模块建模的方式保证变换模型不受domain间语义gap的干扰。

**Brightening.** 和一般的低光照增强任务不同，我们希望在调整光照的同时不引入降噪或色彩重建。而且实际上低光照图片的光照是不均匀的，有的人脸亮一些有的可能非常暗。因此在处理欠曝的同时还要防止过曝问题。

我们的增强模块基于非线性曲线映射方法，由迭代的二次曲线$LE(\cdot)$构成:
$$
LE(x,A)=x+Ax(1-x), \\
LE_n=LE(LE_{n-1};A_n)
$$
其中$LE_0$是输入图像，$LE_n$是n次迭代的结果，$A_n$是像素级三通道校正图，由神经网络估计得到。这种方法不会引入额外的噪声或者人为痕迹。

这种方法的问题是太保守（效果弱）。如Figure 6所示，增强后很多人脸还是暗。这个现象的原因是进一步增强会引入更多噪音，而该方法选择将这些噪音隐藏在黑暗中，也就是不继续增强以保证引入较少噪音。我们通过增大迭代次数来提升增强效果，这样图片会变得更亮，但是缺点是引入了更多噪音和色彩偏差，这一问题留给$H\rightarrow D(H)$过程解决。
![Figure 6](6.png 'Figure 6')

**Noise Synthesis.** 虽然可以通过提高亮度的方式减小像素差异，但是E(L)和H间的差异依然存在。因此我们进一步将这个差异分解为颜色和噪音两部分。通过将颜色分离出来，可以用颜色来引导噪音合成过程。

如Figure 4所示，首先对E(L)进行模糊处理，用模糊的结果$E(L)_{blur}$作为颜色引导。然后训练一个Pix2Pix模型实现$E(L)_{blur}$到E(L)的变换。最后对H进行同样的模糊，用Pix2Pix模型来加噪音。如Figure 5所示，$H_{noise}$成功模仿了E(L)的噪音pattern

**Color Jittering.** 我们希望D(H)的色彩分布与E(L)相同。根据统计分析，扰动范围设定如下：
* 亮度：(0.4, 1.2)
* 对比度：(0.6, 1.4)
* 饱和度：(0.6, 1.4)
* 色调：(0.8, 1.2)

### 3.3. Multi-Task High-Level Adaptation
大多数特征匹配的方法基于对齐、伪标签或者对抗学习。前两个解决不了太大的gap，对抗学习则不稳定。我们选择使用图片自身的信息，也就是用自监督学习的方式。通过强制分类器的跨域共享实现将不同域的特征映射到同一个高维子空间。

**Closing E(L) and H.** 通过基于语义的自监督学习设计的中间任务可以让模型学习理解物体的空间语义信息。我们使用拼图任务作为自监督任务，我们也尝试过旋转以及旋转+拼图，但是测试后发现只用拼图的效果最好。一种可能的解释是WIDER FACE数据集中的很多人脸是画作或广告中的人脸，本身角度就比较奇怪，因此用预测角度的中间任务效果不好。

将一张图片分成3*3，并设定序列数量为30，即30个分类任务。用$p_{jig}$代表序列标签，$\mathcal{L}_c$代表交叉熵损失，有：
$$
\mathcal{L}_{jig}^{E(L)}=\mathcal{L}_c(F_{jig}^{E(L)},p_{jig}^{E(L)}) \\
\mathcal{L}_{jig}^H=\mathcal{L}_c(F_{jig}^H,p_{jig}^H)
$$
其中$F_{jig}$代表对应domain提取的特征。E(L)和H共享分类heads，这样可以强制语义特征映射到同一个空间，从而缩小高层的gaps，最终的loss就是上面两项相加：
$$
\mathcal{L}_{E(L)\leftrightarrow H}=\mathcal{L}_{jig}^{E(L)}+\mathcal{L}_{jig}^H
$$

**Closing H and D(H).** 对比学习的思想是：给定一个序列v，识别它的正样本对和负样本对。目标函数：
$$
\mathcal{L}_q=-\log \Big[\frac{\sigma(v,v^+)}{\sigma(v,v^+)+\sum_{n=1}^N\sigma(v,v_n^-)} \Big] \\
\sigma(x,y)=\exp(x\cdot y/ \tau)
$$
其中$\tau$是超参数。
目标函数：
$$
\tilde{\mathcal{L}}_{H\leftrightarrow D(H)}=
\mathcal{L}_q(H,D(H)^+,H^-) +
\mathcal{L}_q(D(H),H^+,D(H)^-)
$$

**Enhancing E(L).** 还发现通过对比学习的方式增强E(L)的特征是有益的：
$$
\mathcal{L}_{E(L)\uparrow}=\mathcal{L}_q(E(L),E(L)^+,E(L)^-)
$$

**Final objective.** 多任务方式的最终目标函数：
$$
\mathcal{L}=\lambda_{det}\mathcal{L}_{det}+\lambda_{E(L)\leftrightarrow H}\mathcal{L}_{E(L)\leftrightarrow H}+\lambda_{H\leftrightarrow D(H)}\mathcal{L}_{H\leftrightarrow D(H)}+\lambda_{E(L)\uparrow}\mathcal{L}_{E(L)\uparrow}
$$
