# SSH: Single Stage Headless Face Detector

与二阶段proposal-classification检测器不同，SSH在单一阶段直接从一个分类网络靠近输入的卷积层检测人脸。

SSH是headless的，这意味着没有全连接层，去掉了大量的参数。

另外，SSH不使用图像金字塔结构来实现不同尺度人脸的检测，它本身的设计就具有尺度不变性

在一次前向传播中使用不同层的输出同时检测不同尺度的人脸



SOTA CNN-based检测器将图像分类网络转换为二阶段的检测系统。在第一个阶段，使用靠前（靠近输入）的卷积特征图生成一组候选框。第二阶段，被称为网络"head"的分类网络的其余层被用来提取这些候选框的局部特征并对它们进行分类。

分类网络的头部分（head）的计算量非常大，而且在二阶段检测器中，必须对所有候选框进行计算。

最近，使用RPN(Region Proposal Networks)直接检测人脸的方法在WIDER人脸检测基准上获得了SOTA的结果。其对尺度的鲁棒性是通过引入图像金字塔来达到的。但是需要对输入金字塔进行上采样处理，尺度可达5000像素，然后每层都经过一个很深的网络，增加了推理的时间。

与RPN类似，SSH中使用分类网络靠近输入（靠前）的特征图对一组预定义的锚点（anchor）进行回归。与二阶段检测器不同的是，最终的分类结果与anchor的回归是同时进行的。

SSH的设计具有尺度不变性，和采用多尺度的外部金字塔作为输入的方法不同，SSH从底层网络的不同深度来检测人脸，通过在不同层后加入一个高效的卷积检测模块来实现，训练每一个检测模块负责检测一定尺度范围的人脸



## Related Works

### Face Detection

### Single Stage Detectors and Proposal Networks

通过一阶段方式来检测和定位物体的想法已经在一般物体检测领域得到了研究。SSD和YOLO都是通过分类和回归一组固定边框的网格来同时实现检测和分类任务。G-CNN将检测当作一个分段回归问题，一边对其进行分类，一边迭代地将初始的多尺度边界框的网格向物体推进。SSH是一个一阶段检测器；它直接从靠前的卷积层检测人脸，不需要生成阶段。

尽管SSH是一个检测器，它更像一般检测流程中第一阶段使用的物体生成算法。这类算法一般向物体回归一个固定的anchors几何并对每个anchor分配一个物体评分。*MultiBox*使用聚类来定义anchors.零一方面，*RPN*将anchors定义成一些有多种尺度和长宽比的密集box，位置在输入特征图的每个位置中间。SSH采用类似的策略，对人脸的定位和检测时同时进行的。

### Scale Invariance and Context Modeling

尺度不变对于非限制场景下的人脸检测很重要。一般物体检测使用网络靠前位置卷积层的特征图来检测小物体。

SSH能够在不使用图像金字塔的前提下实现单次前向传播过程检出不同尺度人脸。通过跳跃连接（skip connections）和联合训练三个检测模块（卷积层步长不同）来检测大中小三种尺度的人脸。

在二阶段检测器中，通常通过加大proposal周围的窗口尺寸来对上下文信息进行建模，这种方式需要更多内存并且检测时间也更长。SSH仅使用卷积层来达到同样的大窗口尺寸的效果，上下文建模的效率更高。



## Proposed Method

SSH的设计理念是要降低推理耗时、减少内存占用并且具有尺度不变性质。SSH是一个一阶段检测器，意味着与将检测任务分成边界框生成和分类不同，SSH使用卷积层提取的全局信息来同时进行分类和定位。

### General Architecture

![figure2](2.png"Figure 2")

Figure 2展示了SSH的通用框架。

SSH是一个全卷积网络，它通过在特征图后加入检测模块（步长分别为8，16和32，称为$\mathcal{M_1}$, $\mathcal{M_2}$和$\mathcal{M_3}$）对人脸进行定位和分类。检测模块由一个卷积二分类器和一个回归器组成，分别用于检测和定位人脸。

要解决定位这个子问题，SSH对一系列预定义的边界框（称为anchor）向ground-truth进行回归。采用与RPN类似的方法来生成这些边界框，使用密集重叠滑动窗口的方式生成。对于每一个滑动窗口的位置，生成$K$个anchor，这些anchor的中心位置相同但尺寸不同。但是与RPN不同的是我们只使用长宽比为1的边界框来减少边界框的数量。我们发现在实验中，多种长宽比并不能显著提升人脸检测的准确度。更正式的表示是，如果与检测模块$\mathcal{M_i}$相连接的特征图的尺寸为$W_i\times H_i$，就会有长宽比为1的$W_i\times H_i\times K_i$个anchor，它们的尺寸为$\{S_i^1,S_i^2,...S_i^{K_i}\}$



![figure3](3.png"Figure 3")

如Figure3所示，检测模块使用一组卷积层来提取特征，用于人脸检测和定位。其中包含一个简单的上下文模型，用于增强有效感受野。上下文模块输出的通道数（图中的$X$）对于$\mathcal{M_1},\mathcal{M_2},\mathcal{M_3}$分别为128，256，256.最后使用两个卷积层实现边界框回归和分类。

对于$\mathcal{M_i}$的每个卷积位置，分类器都判断滤波器中心位置和对应不同尺度$\{S_i^k\}_{k=1}^K$的窗口是否包含人脸。分类器使用输出通道数为$2\times K$的$1\times 1$卷积层。

回归分支使用输出通道数为$4\times K$的$1\times 1$卷积层。在进行卷积操作时，回归器对每个正样本位置输出尺寸和偏移量的回归值。

### Scale-Invariance Design

非限制场景下图片中的人脸尺寸差异可能非常大。尽管使用多尺度金字塔作为输入并多次前向传播使具有检测不同尺度人脸的能力，但是这么做很慢。与这种方案不同，SSH通过使用网络中的检测模块$\mathcal{M_1}$,$\mathcal{M_2}$和$\mathcal{M_3}$的三个不同卷积层，在一个前向传播的过程中同时检测大尺寸和小尺寸的人脸。检测模块的步长分别为8，16和32，分别用于检测小，中，大三种尺度的人脸。

具体而言，检测模块$\mathcal{M_2}$在VGG-16的conv5-3​层位置进行检测操作。尽管可以将$\mathcal{M_1}$直接放在conv4-3后面，我们使用原用于语义分割和泛物体检测的特征图融合。

为了减少模型的内存需求，使用$1\times 1$卷积将特征图的通道数从512缩减到128。conv5-3特征图经过上采样与conv4-3的特征相加，再经过一个$3\times3$的卷积，融合过程里使用双线性上采样。为了能够检测更大的人脸，在conv5-3后接一个步长为2的max-pooling层，将conv5-3的步长提升至32，这个新加的层后接$\mathcal{M_3}$.

训练阶段，训练每个检测模块$\mathcal{M_i}$检测目标尺度范围内的人脸。

推理阶段，预测的不同尺度的边界框会一起经过nms来组合成最终的检测结果。



### Context Module

二阶段检测器使用增大滑动窗口面积的方式来吸收更多上下文信息。SSH靠使用简单的卷积层的方式来模仿这一策略。

![figure4](4.png"Figure 4")

Figure 4展示了检测模块里的上下文模块。由于通过卷积的方式对锚点（anchors）进行分类和回归，使用更大的滤波器和在二阶段检测器中增大滑动窗口尺寸的效果类似。为此，我们在上下文模块中使用$5\times5$和$7\times7$的滤波器。使用这种方式对上下文信息建模增大了对应层步长的感受野的比例项大小从而增大每个检测模块的目标尺寸。

为了减少参数数量，我们使用连续的$3\times3$滤波器而非更大的卷积核。上下文模块输出的通道数（图中的$X$）对于$\mathcal{M_1},\mathcal{M_2},\mathcal{M_3}$分别为128，256，256.



## Training

使用带动量和权重衰减的随机梯度下降算法训练网络。

使用不同步长的三个检测模块来检测不同尺度的人脸。因此，网络有三个多任务损失，对应每个模块的分类和回归分支。为了区分三个检测模块的不同尺度范围，我们仅对指定到对应尺度范围的人脸的anchor的loss进行反向传播。这个策略是通过将anchors根据各自尺寸分配到不同模块来实现的（例如：较小的anchors分配给$\mathcal{M_1}$），且仅当anchor与gt face的IoU大于0.5的时候将其指定到gt face。这与Faster R-CNN中给每个gt都分配一个IoU最高的anchor的方式不同。因此我们不会反向传播一个模块中与对应anchor尺寸不一致的gt faces的loss。



### Loss Function

SSH使用多任务loss：
$$
\sum\limits_k\frac{1}{N_k^c}\sum\limits_{i\in\mathcal{A_k}}\ell_c(p_i,g_i)+\lambda\sum\limits_k\frac{1}{N_k^r}\sum\limits_{i\in\mathcal{A_k}}\mathcal{I}(g_i=1)\ell_r(b_i,t_i)
\quad\quad\quad(1)
$$
其中$\ell_c$是分类损失，使用standard multinomial logistic loss（交叉熵？）。

下标$k$代表SSH检测模块$\mathcal{M}=\{\mathcal{M_k}\}_1^K$,$\mathcal{A_k}$代表$\mathcal{M_k}$中定义的一组anchors。$\mathcal{M_k}$中第$i$个anchor的类别预测值和真实值分别表示为$p_i$和$g_i$.

当且仅当一个anchor与gt box的IoU大于一个阈值（如0.5）的时候会将二者绑定，当IoU小于阈值（如0.3）的时候将anchor指定为负样本。

$N_k^c$是模块$\mathcal{M_k}$中anchor的数量，它参与到分类损失的计算。

$\ell_r$代表边界框回归损失。用box维度的log-space偏移量和尺度不变平移（scale-invariant translation）来参数化回归空间，并用smooth $\ell_1$ loss计算$\ell_r$.在这个参数化的空间中，$p_i$代表预测的四维变换和尺度变换，$t_i$是$\mathcal{M_k}$中第$i$个anchor对应的gt 回归的目标值。$\mathcal{I(.)}$是指示函数，它限制只有正类anchors才有回归损失，有$N_k^r=\sum_{i\in{\mathcal{A_k}}}I(g_i=1)$.










