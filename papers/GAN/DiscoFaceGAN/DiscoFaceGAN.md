# Disentangled and Controllable Face Image Generation via 3D Imitative-Contrastive Learning

## Abstract
将3D先验嵌入到对抗学习中，训练网络模拟一个分析3D人脸变形和渲染过程的图像的组成。为了解决真实人脸和渲染人脸间的domain gap引入的自由度，进一步引入对比学习通过对比生成图片对来促进解耦

## 1. Introduction
我们调研了使用独立隐变量（包括id信息、表情、姿态、光照和其他噪声）来合成虚拟人物人脸图片的方法。为了得到对上述四种变量的可预测的控制能力，我们通过训练一组VAE将它们转换成参数模型的系数。我们将3DMM和解析渲染过程的先验融入到对抗学习中。引入一组imitative losses强制生成器模仿可解释的图像渲染过程，因此生成由隐变量描述的人脸属性。但是，真实和渲染人脸间的domain gap会导致生成自由度的出现，而这个自由度是无法控制的且会导致负面的变量纠缠。
为了解决生成自由度的问题同时为了增强解纠缠的能力，进一步提出一组对比loss. 对比一对生成图片，然后仅对这一对生成图片共享的完全一样的隐变量引起的外观差异进行惩罚。这样，生成器就会强制每一个隐变量的独立影响表示在最终结果上。对比损失对于隐变量的完全解耦是有关键作用的。
本文使用的模型基于StyleGAN，但是方法可以扩招到其他的GAN上。修改了StyleGAN的隐编码层，将其引入到我们的损失函数。结果表明隐变量可以高度分离，从而可以对生成结果进行精确地控制。我们进一步分析了学习得到的StyleGAN隐空间并发现一些支持因子分解的有意义的属性。我们的方法可以用于将真实图片嵌入到解纠缠的隐空间

## 2. Related Work

![Figure 2](2.png "Figure 2")
## 3. Approach
给定一组真是人脸图片$\mathcal{Y}$,目标是训练一个网络G从随机噪声z生成现实的人脸图片x，随机噪声z由多个独立变量$z_i\in \mathbb{R}^{N_i}$组成，每一个都服从正态分布。
考虑五个独立的因素：id、表情、光照、姿态和随机噪声。在标准的GAN中，会使用一个判别器D来与G进行对抗。为可获得解纠缠和可解释的隐空间，我们将3D先验引入到一个模仿-对比学习范式，见Figure 2

### 3.1. Imitative Learning
引入3DMM模型并训练生成器模仿渲染后的3D人脸。有参数$\lambda \doteq [\alpha,\beta,\gamma,\theta]$,分别为对应id、表情、光照和姿态。
为了能够进行模仿，首先将$z$空间转换为$\lambda$空间。通过在从真实数据集$\mathcal{Y}$中提取的$\lambda$样本上训练VAE模型实现这个空间的转换。具体使用3D人脸重建网络获得所有训练图片的系数然后分别训练$\alpha,\beta,\gamma,\theta$四个VAE. 训练完成后丢掉编码器只保留解码器($V_i,i=1,2,3,4$)用于从$z$空间转换为$\lambda$空间。
在训练中，从标准正态分布采样$z=[z_1,...z_5]$，将它映射到$\lambda$，然后把$\lambda$传入生成器G和渲染器，分别获得生成的人脸$x$和渲染的人脸$\hat{x}$.注意到其实可以将$z$或者$\lambda$传入G，实际上没差别。使用$\lambda$的优势在于控制人脸属性，因为$\lambda$是可解释的。
