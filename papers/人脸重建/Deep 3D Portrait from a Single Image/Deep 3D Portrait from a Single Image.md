# Deep 3D Portrait from a Single Image

## Abstract
单张人像图片的头部3D重建方法。用一个参数化的3D人脸模型和一个包括头发和耳朵的头部其他区域的深度图来表示头部几何信息。提出一个二阶段范式来学习从人脸图重建3D头部的方法，首先学习使用自重建从单张图片获取人脸形状，然后使用立体匹配方法的成对图片学习头发和耳朵几何信息。第二步在第一步输出的基础上，不仅提升精度而且保证头部的全局几何一致性。

## 1. Introduction
学习单张图片的3D头部几何重建至少需要面对两个挑战。首先，人像图片的gt中携带的3D几何信息对于CNN的训练来说太少了，尤其是头发这种在3D扫描中会出现问题的部分。为了解决这个问题，提出一个头部几何估计的无监督学习流程。人脸部分则直接使用3DMM方法回归得到3DMM参数。而对于头发和耳朵，提出利用视角变化，在从视频提取的图片对上进行训练。第二个挑战是如何保证连续的头部结构，因为它是由两个单独的部分构成的。提出一个两步形状学习范式，其中使用复原的人脸几何信息作为深度网络的条件输入，并设计兼顾人脸和头发几何信息的层一致性的loss函数。

## 3. Overview and Preprocessing
框架入Figure 1所示。在图像经过预处理之后，运行两阶段3D重建，通过两个CNN来估计3D头部姿态和形状。针对头部姿态操作，首先调整重建的3D模型的姿态并将其重新映射到图片平面，然后使用一个优化CNN获取最终结果。
![Figure 1](1.png "Figure 1")

**Preprocessing.** 先对齐，然后进行人脸分割得到头部区域$\mathcal{S}$,包含面部、头发和耳朵区域

## 4. Single-Image 3D Head Reconstruction
使用的相机透视模型的焦距是根据经验选择的。头部姿态由旋转矩阵$\textbf{R}\in \text{SO}(3)$和平移矩阵$\textbf{t}\in \mathcal{R}^3$确定的，且参数化为$\textbf{p}\in \mathcal{R}^7$，通过四元数表示其旋转。

### 4.1. Face Reconstruction and Pose Estimation
3DMM方法

### 4.2. Hair&Ear Depth Estimation
下一步是为头部的其他区域估计深度图
由于缺少真实的深度数据，所以使用视频中图片对来训练一个网络。只在训练的时候使用成对数据
令$I_1,I_2$代表一个人在视频中拥有不同头部姿态$(\textbf{R}_1, \textbf{t}_1),(\textbf{R}_2, \textbf{t}_2)$的一对图片。目标是训练一个网络来预测它们的深度图$d_1,d_2$. 在训练前，首先运行一个传统的三角分割获取两个图片对应的2D网格图。给定估计的深度图$d_1$,可以通过逆投影重建一个3D网格图$\textbf{H}_1$. 然后可以通过$(\textbf{R}_2\textbf{R}_1^{-1},-\textbf{R}_2\textbf{R}_1^{-1}\textbf{t}_1+\textbf{t}_2)$将$\textbf{H}_1$变换到$I_2$的相机视角并投影到图片平面上得到合成后的图像$I_2'$. 通过同样的步骤可以从$I_2,d_2$生成$I_1'$.整个流程可微，因此可以用来训练深度预测网络，loss函数如下。
在立体匹配中，首先通过最小化亮度误差来强制颜色一致性约束
$$
l_{color}=\int_{\mathcal{H}_2'}{\lVert I_2'(d_1)-I_2 \rVert_1} + \int_{\mathcal{H}_1'}{\lVert I_1'(d_2)-I_1 \rVert_1}
$$
其中$\mathcal{H}_2'=\mathcal{H}_2'(\mathcal{H}_1,d_1)$