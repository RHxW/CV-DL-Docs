# Attention Is All You Need

## Abstract

主要的序列转导模型(sequence transduction models)都是基于复杂的循环或者包含一个编码器和一个解码器的卷积神经网络。性能最佳的模型同样通过一种注意力机制将编码器和解码器连接到一起。我们提出一个新的简单的网络架构，Transformer，只基于注意力机制而完全不需要循环或者卷积。



## 1 Introduction

循环神经网络、长短期记忆、以及特别是门控循环神经网络是序列建模和转导问题如语言建模和机器翻译等方向的sota的网络架构。

循环模型会典型地沿着输入和输出序列的符号位置进行因子化计算。